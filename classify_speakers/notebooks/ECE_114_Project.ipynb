{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUGt3c3glZcm"
      },
      "source": [
        "##ECE 114 Project: Speaker Region Identification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U45DldLRvjGB"
      },
      "source": [
        "In this project, we'll train a machine learning algorithm to classify speakers by regional dialect.  We will use speech samples from the Corpus of Regional African American Language (CORAAL - https://oraal.uoregon.edu/coraal) with speakers each belonging to one of five different US cities: 1) Rochester, NY (ROC), 2) Lower East Side, Manhattan, NY (LES), 3) Washington DC (DCB), 4) Princeville, NC (PRV), or 5) Valdosta, GA (VLD).\n",
        "\n",
        "The project files can be downloaded from [this link](https://ucla.box.com/s/w7s25pffjtjhkphhcb5rpjepi1nt9rg7)\n",
        "\n",
        "To do this, we will first extract features from the audio files and then train a classifier to predict the city of origin of the utterance's speaker.  The goal is to extract a feature that contains useful information about regional dialect characteristics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZGgwhT7lsNZ"
      },
      "source": [
        "##1. Setting up the data directories and Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSI8N_Imwiwz"
      },
      "source": [
        "Store a copy of the project files in your google drive.  \n",
        "\n",
        "Make sure that the 'project_data' folder is stored in the top level of your google drive.  Otherwise, you will need to change the corresponding paths in the remainder of the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srmiFaC9xSw4"
      },
      "source": [
        "Mount your google drive. This will give this notebook read/write access to data stored in your google drive.  You can either do this in the file browser on the left side of this notebook or by running the code snippet below.\n",
        "\n",
        "It is recommended that you use your UCLA google account for this project, as it has more storage than a standard google account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEmYBGxdve23"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUKk6flWvYVB"
      },
      "source": [
        "To run this project on your local system, replace the corresponding file paths to the locations of the project files on your local machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hon860bcmLDD"
      },
      "source": [
        "## 2. Getting familiar with the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaEIHyQByAiy"
      },
      "source": [
        "\n",
        "Let's take a moment to understand the data.  The original CORAAL dataset consists of ~85 different speakers, each from one of five cities.  The audio files are names with the convention: DCB_se1_ag1_f_03.  Here, DCB is the city code, se1 denotes the socioeconomic group of the speaker, ag1 denotes the age group of the speaker, f denotes female, and 03 denotes the participant number.  These unique combinations of identifiers mark the speaker.  \n",
        "\n",
        "The dataset has been preprocessed to only include audio segments greater than 10 seconds in length. there are a number of audio snippets of at least 10sec in length.  Those segments are numbered with the appending tag _seg_number for each segment.\n",
        "\n",
        "You can also try listening to any segment like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "NAiO3g1e9oN7",
        "outputId": "93344445-0955-484e-a9a3-6fc6e92ca43d"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "sr = 44100\n",
        "\n",
        "Audio(filename= \"../../datasets/\", rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Uu12stenzcx"
      },
      "source": [
        "## 3. Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QpW8VRs9t_c"
      },
      "source": [
        "As a baseline, we will be using the average mfcc value over time from the Librosa Python library. Your job will be to choose better features to improve performance on the test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNEtHr-TapYg"
      },
      "source": [
        "We first define a pair of functions to create features and labels for our classification model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8nOljY9x9Bo"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def extract_feature(audio_file, n_mfcc=13):\n",
        "\n",
        "  '''\n",
        "  Function to extract features from a single audio file given its path\n",
        "  Modify this function to extract your own custom features\n",
        "  '''\n",
        "\n",
        "  audio,fs = torchaudio.load(audio_file)\n",
        "  audio = audio.numpy().reshape(-1)\n",
        "\n",
        "  # replace the following features with your own\n",
        "  mfccs = librosa.feature.mfcc(y=audio, sr=fs, n_mfcc=n_mfcc)\n",
        "  feat_out = np.mean(mfccs,axis=1)\n",
        "\n",
        "  lpcs = librsioa.feature.lpc()\n",
        "\n",
        "  return feat_out\n",
        "\n",
        "\n",
        "def get_label(file_name):\n",
        "  '''\n",
        "  Function to retrieve output labels from filenames\n",
        "  '''\n",
        "  if 'ROC' in file_name:\n",
        "    label=0\n",
        "  elif 'LES' in file_name:\n",
        "    label=1\n",
        "  elif 'DC' in file_name:\n",
        "    label=2\n",
        "  elif 'PRV' in file_name:\n",
        "    label=3\n",
        "  elif 'VLD' in file_name:\n",
        "    label=4\n",
        "  else:\n",
        "    raise ValueError('invalid file name')\n",
        "  return label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAe_LnvKbCO_"
      },
      "source": [
        "Let us now call these functions to extract the features and labels from the train directory\n",
        "\n",
        "Note: This cell might not update the progress bar continuously, but for the baseline MFCC features should take a maximum of 30 minutes to execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XdmLAGFYkaG",
        "outputId": "52677e0d-8d35-40e7-8d65-f19b2755bf89"
      },
      "outputs": [],
      "source": [
        "\n",
        "#First we obtain the list of all files in the train directory\n",
        "train_files = glob('drive/MyDrive/project_data/train/*.wav')\n",
        "\n",
        "#Let's sort it so that we're all using the same file list order\n",
        "#and you can continue processing the features from a given file if it stops\n",
        "#partway through running\n",
        "train_files.sort()\n",
        "\n",
        "train_feat=[]\n",
        "train_label=[]\n",
        "\n",
        "for wav in tqdm(train_files):\n",
        "\n",
        "  train_feat.append(extract_feature(wav))\n",
        "  train_label.append(get_label(wav))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UkyzBSo-bwOo",
        "outputId": "539dc532-ed47-4d97-a205-a74670e4465a"
      },
      "outputs": [],
      "source": [
        "#Now we obtain the list of all files in the test directory\n",
        "test_files = glob('drive/MyDrive/project_data/test/*.wav')\n",
        "\n",
        "#Similar to above, we sort the files\n",
        "test_files.sort()\n",
        "\n",
        "test_feat=[]\n",
        "test_label=[]\n",
        "\n",
        "for wav in tqdm(test_files):\n",
        "\n",
        "  test_feat.append(extract_feature(wav))\n",
        "  test_label.append(get_label(wav))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw2ju2S9oUD-"
      },
      "source": [
        "## 4. Model Training and Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssNxb69kMSCg"
      },
      "source": [
        "Now we'll train the backend system to predict the regions from the input features.  We'll use an xgboosted decision tree for this.  An advantage of this model is that we can also parse the decision tree and measure the impact of different features in the end result for explainability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DV1n9ZdOMzA2",
        "outputId": "a5054dd1-bdfd-468f-c00a-6e40d91749c0"
      },
      "outputs": [],
      "source": [
        "#Install shap library\n",
        "# !pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FdlSdywtJ0jm",
        "outputId": "ad5ee732-c0c4-4b71-ce96-7da7d2def476"
      },
      "outputs": [],
      "source": [
        "import xgboost\n",
        "import numpy as np\n",
        "import shap\n",
        "import pandas as pd\n",
        "\n",
        "#Format input data\n",
        "\n",
        "#Edit this variable to create a list that contains your feature names\n",
        "feat_names=['mfcc_' +str(n) for n in range(len(train_feat[0]))]\n",
        "\n",
        "train_feat_df = pd.DataFrame(data=np.stack(train_feat), columns=feat_names)\n",
        "y_train=np.stack(train_label)\n",
        "\n",
        "\n",
        "test_feat_df = pd.DataFrame(data=np.stack(test_feat), columns=feat_names)\n",
        "y_test=np.stack(test_label)\n",
        "\n",
        "\n",
        "\n",
        "#you could just pass in the matrix of features to xgboost\n",
        "#but it looks prettier in the shap explainer if you format it\n",
        "#as a dataframe.\n",
        "\n",
        "\n",
        "model = xgboost.XGBClassifier()\n",
        "model.fit(train_feat_df,y_train)\n",
        "\n",
        "print(\"Train Acc =\", np.sum(y_train==model.predict(train_feat_df))/len(y_train))\n",
        "\n",
        "print(\"Test Acc =\", np.sum(y_test==model.predict(test_feat_df))/len(y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU1Zv35-Xdfh"
      },
      "source": [
        "To save a dataframe of features, uncomment and run the following block of code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zVCxaJuqXj8S"
      },
      "outputs": [],
      "source": [
        "# train_feat_df.to_csv('drive/MyDrive/project_data/current_features.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS7zsBisXwgt"
      },
      "source": [
        "To Load a preexisting dataframe of features (saved from a previous notebook), run the following cell and then train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AzXTGihBX8Py"
      },
      "outputs": [],
      "source": [
        "# train_feat_df = pd.read_csv('drive/MyDrive/project_data/myfeat_train.csv')\n",
        "# test_feat_df = pd.read_csv('drive/MyDrive/project_data/myfeat_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V22hV2OenttX"
      },
      "source": [
        "The following cells are to extract features from MATLAB. Ensure that you've run the baseline once before running the cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRhRhr2DoYTp"
      },
      "source": [
        "Saving list of train and test files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heJ0zhpQoHXy"
      },
      "outputs": [],
      "source": [
        "# Note: we save the list of files to ensure the labels match the utterances\n",
        "# You can omit this step if you plan on extracting the labels in MATLAB\n",
        "# But will need to rewrite code in other parts of the notebook\n",
        "\n",
        "# with open('drive/MyDrive/project_data/train_files.txt', 'w') as f:\n",
        "#     for line in train_files:\n",
        "#         f.write(f\"{line}\\n\")\n",
        "\n",
        "# with open('drive/MyDrive/project_data/test_files.txt', 'w') as f:\n",
        "#     for line in test_files:\n",
        "#         f.write(f\"{line}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z35bywV-pOXS"
      },
      "source": [
        "After extracting features using wrapper.m, run the following cell to retrieve a dataframe containing the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGCMJkvIpx7D"
      },
      "outputs": [],
      "source": [
        "# train_feat_df = pd.read_csv('drive/MyDrive/project_data/myfeat_train.csv')\n",
        "# test_feat_df = pd.read_csv('drive/MyDrive/project_data/myfeat_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-E5w5FsoeLK"
      },
      "source": [
        "## 5. Interpreting Results and Explainability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x11o8qaNfSYT"
      },
      "source": [
        "To see the impact different features have on the model, we create a plot of the feature importances. The features are listed top to bottom in order of how important they were to the decision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7aXxyyBeLkE"
      },
      "outputs": [],
      "source": [
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(train_feat_df)\n",
        "shap.summary_plot(shap_values, train_feat_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlzXmcA-fd7x"
      },
      "source": [
        "And we can see a confusion matrix of the mispredictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5xFg3P2fqj_"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, model.predict(test_feat_df))\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['ROC','LES','DCB','PRV','VLD'])\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
